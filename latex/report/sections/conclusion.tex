\chapter{Future Plans}
\section{Motion Segmentation }
Future work will involve the following:
\begin{itemize}
\item Development of an API for processing a gesture language. Gestures will be used to direct the robot to identify objects of particular category and follow them using the motion segmentation algorithm with a neuromorphic vision sensor.
  
\item Develop a method to render point-cloud information from the scene in the VR room. This will be possible by transferring data encoded in $XDM$ format.
	
\item An algorithm to enable tracking-following will be developed by utilizing the previous work on motion segmentation. This algorithm will develop a computation layer on top of the motion segmentation algorithm to localize on specific objects in the environment. A study will be performed to compare and quantify the results obtained, and the paper submitted to Frontiers in Neuromorphic Engineering. 
\end{itemize}

\section{Vibro-Tactile Haptic Glove}
To establish bidirectional communication pathway between the haptic
gloves and the virtual reality platform, we are working towards
developing wireless communication protocol between the AR/VR platform
and haptic gloves.

Also, we are currently developing a fourth generation of haptic glove with amplitude and frequency modulation capabilities. With this generation of haptic glove, we aim to investigate and render virtual objectâ€™s surface information such as texture, 3-D geometric shape, etc.  


\section{CAVE VR}
In order to implement a working gesture language system, data
exploration will be conducted. Common features will be extracted from
time sequence data.

We will use HMM as the basic model for marker based gesture
recognition. Benchmarks will also be tested in order to measure the
accuracy and efficiency of the gesture system.


